name: "E2E: Build Postiron (Ubuntu)"

# Cache Save Strategy:
# This workflow has a save_cache parameter to prevent race conditions when multiple jobs
# try to save the same cache key simultaneously. Only ONE job per calling workflow should
# set save_cache: true. Examples:
# - test-merge.yml: unit-tests saves, setup does not
# - test-full-suite.yml: setup saves (default true), all others do not
# - test-cross-browser.yml: setup saves (default true), all others do not

on:
  workflow_call:
    inputs:
      save_cache:
        required: false
        description: "Whether to save caches after the run (only one job per workflow should save to avoid race conditions)"
        type: boolean
        default: true  # Default to true for backwards compatibility (test-full-suite.yml, test-cross-browser.yml)

permissions:
  id-token: write
  contents: read
  packages: read

jobs:
  build:
    name: build-ubuntu
    timeout-minutes: 25
    runs-on: ubuntu-latest-8x
    container:
      image: ghcr.io/posit-dev/positron-ubuntu24-amd64:64
      options: --user 0:0
      # Static PAT is needed because the bot can't pass a token to the job for security reasons
      credentials:
        username: ${{ secrets.POSITRON_GITHUB_RO_USER }}
        password: ${{ secrets.POSITRON_GITHUB_RO_PAT }}
    services:
      postgres:
        image: ghcr.io/posit-dev/positron-postgres-ubuntu24-amd64:64
        credentials:
          username: ${{ secrets.POSITRON_GITHUB_RO_USER }}
          password: ${{ secrets.POSITRON_GITHUB_RO_PAT }}
        ports:
          - 5432:5432
        env:
          POSTGRES_USER: ${{ secrets.E2E_POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.E2E_POSTGRES_PASSWORD }}
          POSTGRES_DB: ${{ secrets.E2E_POSTGRES_DB }}
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      DOCKER_CONFIG: /tmp/.docker # Ensure Docker client doesn't try to read a root-owned config file in the container
      POSITRON_BUILD_NUMBER: 0 # CI skips building releases
      _R_CHECK_FUTURE_FILE_TIMESTAMPS_: false # this check can be flaky in the R pkg tests
      _R_CHECK_CRAN_INCOMING_: false
      _R_CHECK_SYSTEM_CLOCK_: false
      AWS_S3_BUCKET: positron-test-reports
      E2E_POSTGRES_USER: ${{ secrets.E2E_POSTGRES_USER }}
      E2E_POSTGRES_PASSWORD: ${{ secrets.E2E_POSTGRES_PASSWORD }}
      E2E_POSTGRES_DB: ${{ secrets.E2E_POSTGRES_DB }}
      E2E_CONNECT_SERVER: ${{ secrets.E2E_CONNECT_SERVER}}
      E2E_CONNECT_APIKEY: ${{ secrets.E2E_CONNECT_APIKEY}}
      R_LIBS_SITE: /usr/local/lib/R/site-library
      R_LIBS_USER: /usr/local/lib/R/site-library
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
      RETICULATE_PYTHON: /root/.venv/bin/python
      HOME: /root

    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Ensure Docker config dir is writable
        run: |
          mkdir -p /tmp/.docker
          chmod 700 /tmp/.docker

      - name: Restore caches
        id: restore-caches
        uses: ./.github/actions/restore-build-caches

      - name: Apply patches when cache hits
        if: steps.restore-caches.outputs.cache-npm-core-hit == 'true'
        run: |
          echo "Cache hit - applying patches to cached node_modules"
          npx patch-package

      - name: Install node dependencies
        if: steps.restore-caches.outputs.cache-npm-core-hit != 'true' || steps.restore-caches.outputs.cache-npm-extensions-hit != 'true' || steps.restore-caches.outputs.cache-ark-hit != 'true' || steps.restore-caches.outputs.cache-kallichore-hit != 'true'
        uses: nick-fields/retry@v3
        env:
          PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD: 1
          ELECTRON_SKIP_BINARY_DOWNLOAD: 1
          POSITRON_GITHUB_RO_PAT: ${{ github.token }}
          POSITRON_PARALLEL_INSTALL: '1'
          POSITRON_NPM_CONCURRENCY: '10'
          NPM_CONFIG_AUDIT: 'false'              # Skip security audit during install (speeds up install)
          NPM_CONFIG_FUND: 'false'               # Skip funding messages
          NPM_CONFIG_UPDATE_NOTIFIER: 'false'    # Skip update notifications
        with:
          timeout_minutes: 30
          max_attempts: 3
          retry_wait_seconds: 5
          shell: bash
          command: bash scripts/install-npm-parallel.sh

      - name: Install E2E test dependencies
        run: npm --prefix test/e2e ci --prefer-offline --no-audit --no-fund

      - name: Compile Positron and Download Electron
        run: npm exec -- npm-run-all --max-old-space-size=8192 -p compile "electron x64"

      - name: Install Playwright browsers
        if: ${{ steps.restore-caches.outputs.cache-playwright-hit != 'true' || steps.restore-caches.outputs.verify-playwright-outcome == 'failure' }}
        run: |
          echo "Cache miss - Installing Playwright browser binaries into $HOME/.cache/ms-playwright"
          npx playwright install --with-deps

      # Downloads Builtin Extensions (needed for integration & e2e testing)
      - name: Prelaunch
        run: npm run prelaunch

      - name: Save caches
        if: ${{ inputs.save_cache }}
        uses: ./.github/actions/save-build-caches
        with:
          cache-npm-core-hit: ${{ steps.restore-caches.outputs.cache-npm-core-hit }}
          cache-npm-extensions-hit: ${{ steps.restore-caches.outputs.cache-npm-extensions-hit }}
          cache-playwright-hit: ${{ steps.restore-caches.outputs.cache-playwright-hit }}
          cache-builtins-hit: ${{ steps.restore-caches.outputs.cache-builtins-hit }}
          cache-ark-hit: ${{ steps.restore-caches.outputs.cache-ark-hit }}
          cache-kallichore-hit: ${{ steps.restore-caches.outputs.cache-kallichore-hit }}
          extensions-hash: ${{ steps.restore-caches.outputs.extensions-hash }}
          package-locks-hash: ${{ steps.restore-caches.outputs.package-locks-hash }}

      - name: Move Positron License
        run: |
          mv /positron-license /__w/positron || true
          printf "%s" "${{ secrets.POSITRON_DEV_LICENSE }}" > /__w/positron/positron-license/pdol/target/debug/pdol_rsa || true

      - name: Check remote QA content version
        id: qa-remote-check
        continue-on-error: true
        run: |
          echo "Checking latest commit in qa-example-content..."
          REMOTE_SHA=$(git ls-remote https://github.com/posit-dev/qa-example-content.git HEAD | awk '{print $1}')
          echo "remote-sha=$REMOTE_SHA" >> "$GITHUB_OUTPUT"
          echo "Latest qa-example-content commit: $REMOTE_SHA"

      - name: Restore QA example content cache
        id: cache-qa-content
        uses: actions/cache/restore@v4
        with:
          path: /tmp/qa-example-content-cache
          # Cache key based on remote commit SHA for accurate freshness
          # Falls back to any previous cache if remote check failed
          key: qa-content-${{ steps.qa-remote-check.outputs.remote-sha }}-v1
          restore-keys: |
            qa-content-

      - name: Verify cached content freshness
        id: verify-cache
        if: steps.cache-qa-content.outputs.cache-hit == 'true'
        continue-on-error: true
        run: |
          if [ -f /tmp/qa-example-content-cache/.cached-commit ]; then
            CACHED_SHA=$(cat /tmp/qa-example-content-cache/.cached-commit)
            REMOTE_SHA="${{ steps.qa-remote-check.outputs.remote-sha }}"
            echo "Cached commit: $CACHED_SHA"
            echo "Remote commit: $REMOTE_SHA"
            if [ "$CACHED_SHA" != "$REMOTE_SHA" ]; then
              echo "Cache is stale - will re-clone"
              echo "cache-is-fresh=false" >> "$GITHUB_OUTPUT"
              exit 0
            else
              echo "Cache is fresh"
              echo "cache-is-fresh=true" >> "$GITHUB_OUTPUT"
            fi
          else
            echo "No .cached-commit file found - will re-clone"
            echo "cache-is-fresh=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Clone QA example content
        if: |
          steps.cache-qa-content.outputs.cache-hit != 'true' ||
          steps.verify-cache.outputs.cache-is-fresh == 'false'
        run: |
          echo "Cloning fresh QA example content..."
          rm -rf /tmp/qa-example-content-cache || true
          git clone --depth=1 --branch main https://github.com/posit-dev/qa-example-content.git /tmp/qa-example-content-cache || true
          if [ -d /tmp/qa-example-content-cache ]; then
            COMMIT_SHA=$(cd /tmp/qa-example-content-cache && git rev-parse HEAD)
            echo "$COMMIT_SHA" > /tmp/qa-example-content-cache/.cached-commit
            echo "Cloned QA content at commit: $COMMIT_SHA"
          fi

      - name: Save QA example content cache
        if: |
          steps.cache-qa-content.outputs.cache-hit != 'true' ||
          steps.verify-cache.outputs.cache-is-fresh == 'false'
        uses: actions/cache/save@v4
        with:
          path: /tmp/qa-example-content-cache
          key: qa-content-${{ steps.qa-remote-check.outputs.remote-sha }}-v1

      - name: Create Build Artifact
        run: |
          # Ensure QA example content is bundled so downstream runners that lack network
          # access can still prepare test fixtures. Copy from /tmp cache into the workspace path
          # under positron/test/e2e/qa-example-content-cache.
          mkdir -p /__w/positron/test/e2e
          if [ -d "/tmp/qa-example-content-cache" ]; then
            echo "Copying cached QA content to workspace"
            cp -R /tmp/qa-example-content-cache /__w/positron/test/e2e/qa-example-content-cache || true
          else
            echo "Warning: QA content cache not found at /tmp/qa-example-content-cache"
          fi

          # Create a tarball of the entire positron workspace. Exclude .git to avoid including repository history.
          mkdir -p /tmp/artifacts
          # Install zstd and pigz if apt is available so we can produce fast zstd archives.
          if command -v apt-get >/dev/null 2>&1; then
            echo "Installing pigz and zstd for faster compression (if not already present)"
            DEBIAN_FRONTEND=noninteractive apt-get update -y || true
            DEBIAN_FRONTEND=noninteractive apt-get install -y pigz zstd || true
          fi

          # Prefer zstd for best compress+decompress speed and smaller output (requires zstd on unpack side).
          # Fall back to pigz (parallel gzip) if zstd is not available, else gzip -1 as a final fallback.
          if command -v zstd >/dev/null 2>&1; then
            echo "Using zstd (multithreaded) for compression"
            # Place options (exclude) before the filenames so tar respects them.
            # Only exclude root .git, not nested ones (e.g., qa-example-content-cache/.git)
            tar -C /__w \
              --exclude='positron/.git' \
              --exclude='positron/.npm-cache' \
              --exclude='positron/.pip-cache' \
              --use-compress-program='zstd -T0 -1' \
              -cf /tmp/artifacts/positron-build.tar.zst positron || true
          elif command -v pigz >/dev/null 2>&1; then
            echo "zstd not available; using pigz (parallel gzip) for compression"
            tar -C /__w \
              --exclude='positron/.git' \
              --exclude='positron/.npm-cache' \
              --exclude='positron/.pip-cache' \
              --use-compress-program=pigz \
              -cf /tmp/artifacts/positron-build.tar.gz positron || true
          else
            echo "zstd and pigz not available; using gzip -1 for faster compression"
            # Use gzip -1 via a pipe to avoid using the deprecated GZIP env var
            tar -C /__w \
              --exclude='positron/.git' \
              --exclude='positron/.npm-cache' \
              --exclude='positron/.pip-cache' \
              -cf - positron | gzip -1 > /tmp/artifacts/positron-build.tar.gz || true
          fi

      - name: Upload Build Artifact
        uses: actions/upload-artifact@v4
        with:
          name: "positron-build"
          path: /tmp/artifacts
          retention-days: 1
          compression-level: 0  # Skip GitHub compression since we use tar.zst
