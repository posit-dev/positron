# Positron LLM Inspect AI Testings

This documents the process for evaluating the performance of the Positron Assistant.

This testing process consists of 2 parts:
1. A playwright e2e test that runs the assistant in a controlled environment and captures the responses.
2. An inspect-ai evaluation that scores the responses based on a predefined rubric.

### `response-dataset.json`
This file contains the dataset of questions, expected answers, and the model's responses. Each entry includes:

- `id`: A unique identifier for the test case.
- `description`: A brief description of the test case.
- `mode`: The mode of interaction (e.g., "Ask", "Edit". or "Agent").
- `question`: The question or prompt given to the assistant.
- `model_response`: The actual response generated by the assistant. This is blank and populated during the e2e test.
- `target`: The expected answer or criteria for evaluating the response.

### Playwright E2E Test
Located in 'test\e2e\tests\positron-assistant\inspect-ai.test.ts', this test runs the assistant with the questions from `response-dataset.json` and captures the responses.

It relies on an API key for the LLM, currently Anthropic only. This should to be stored in the environment variable `ANTHROPIC_API_KEY`.

### Inspect AI Evaluation
Located in `test\assistant-inspect-ai\json-response-eval.py`, this python script evaluates the responses using the Inspect AI framework.It compares the `model_response` against the `target` for each test case and generates a report.

- It requires an OpenAI API key, which should be stored in the environment variable `ANTHROPIC_API_KEY`.
- The script is designed to be run after the Playwright E2E test to evaluate the captured responses.
- Use the `requirements.txt` file to install the necessary python dependencies.

### Running the Inspect AI Evaluation

```bash
cd test\assistant-inspect-ai
pip install -r requirements.txt
inspect eval .\json-response-eval.py
```

This will generate a report in the `.\logs` directory.

It's recommended to install the [Inspect AI VSCode extension](https://marketplace.visualstudio.com/items?itemName=ukaisi.inspect-ai) for easier viewing of the evaluation results.
